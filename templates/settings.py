import streamlit as st
import os
import requests
import json
from config import settings

def show_settings():
    """æ˜¾ç¤ºç³»ç»Ÿè®¾ç½®é¡µé¢"""
    st.title("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
    st.markdown("é…ç½®å’Œç®¡ç†OAæ–‡æ¡£å¤„ç†ç³»ç»Ÿçš„å„é¡¹å‚æ•°")
    
    # åˆ›å»ºé€‰é¡¹å¡
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ”§ åŸºæœ¬é…ç½®", 
        "â˜ï¸ S3å­˜å‚¨", 
        "ğŸ¤– AIé…ç½®", 
        "ğŸ“š Difyé›†æˆ", 
        "ğŸ¥ ç³»ç»Ÿå¥åº·"
    ])
    
    with tab1:
        show_basic_settings()
    
    with tab2:
        show_s3_settings()
    
    with tab3:
        show_ai_settings()
    
    with tab4:
        show_dify_settings()
    
    with tab5:
        show_system_health()

def show_basic_settings():
    """æ˜¾ç¤ºåŸºæœ¬é…ç½®"""
    st.subheader("ğŸ“‹ åŸºæœ¬é…ç½®")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**æ•°æ®åº“é…ç½®**")
        
        # æ•°æ®åº“è¿æ¥çŠ¶æ€
        db_status = check_database_connection()
        if db_status:
            st.success("âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸")
        else:
            st.error("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
        
        # æ˜¾ç¤ºæ•°æ®åº“ä¿¡æ¯ï¼ˆè„±æ•ï¼‰
        db_url = os.getenv("DATABASE_URL", "æœªé…ç½®")
        if db_url != "æœªé…ç½®":
            # è„±æ•æ˜¾ç¤º
            masked_url = mask_sensitive_info(db_url)
            st.code(f"æ•°æ®åº“URL: {masked_url}")
        else:
            st.warning("âš ï¸ æ•°æ®åº“URLæœªé…ç½®")
        
        st.markdown("**Redisé…ç½®**")
        redis_url = os.getenv("REDIS_URL", "redis://localhost:6379/0")
        redis_status = check_redis_connection()
        
        if redis_status:
            st.success("âœ… Redisè¿æ¥æ­£å¸¸")
        else:
            st.error("âŒ Redisè¿æ¥å¤±è´¥")
        
        masked_redis = mask_sensitive_info(redis_url)
        st.code(f"Redis URL: {masked_redis}")
    
    with col2:
        st.markdown("**æ–‡æ¡£å¤„ç†é…ç½®**")
        
        max_file_size = settings.max_file_size / (1024 * 1024)  # è½¬æ¢ä¸ºMB
        st.info(f"ğŸ“ æœ€å¤§æ–‡ä»¶å¤§å°: {max_file_size:.0f} MB")
        
        supported_formats = ", ".join(settings.supported_formats)
        st.info(f"ğŸ“„ æ”¯æŒçš„æ ¼å¼: {supported_formats}")
        
        st.markdown("**ç¯å¢ƒä¿¡æ¯**")
        st.info(f"ğŸƒâ€â™‚ï¸ è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if settings.debug else 'å…³é—­'}")
        
        # ç³»ç»Ÿç¯å¢ƒå˜é‡æ£€æŸ¥
        required_vars = [
            "DATABASE_URL", "REDIS_URL", "S3_ACCESS_KEY", 
            "S3_SECRET_KEY", "OPENAI_API_KEY", "DIFY_API_KEY"
        ]
        
        st.markdown("**ç¯å¢ƒå˜é‡æ£€æŸ¥**")
        for var in required_vars:
            value = os.getenv(var)
            if value:
                st.success(f"âœ… {var}")
            else:
                st.error(f"âŒ {var} - æœªè®¾ç½®")

def show_s3_settings():
    """æ˜¾ç¤ºS3å­˜å‚¨é…ç½®"""
    st.subheader("â˜ï¸ S3å­˜å‚¨é…ç½®")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**è¿æ¥é…ç½®**")
        
        # S3è¿æ¥çŠ¶æ€
        s3_status = check_s3_connection()
        if s3_status['connected']:
            st.success("âœ… S3è¿æ¥æ­£å¸¸")
        else:
            st.error(f"âŒ S3è¿æ¥å¤±è´¥: {s3_status.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # æ˜¾ç¤ºS3é…ç½®ï¼ˆè„±æ•ï¼‰
        s3_config = {
            "Bucket": os.getenv("S3_BUCKET_NAME", "æœªé…ç½®"),
            "Region": os.getenv("S3_REGION", "æœªé…ç½®"),
            "Endpoint": os.getenv("S3_ENDPOINT_URL", "é»˜è®¤"),
            "Access Key": mask_sensitive_info(os.getenv("S3_ACCESS_KEY", "æœªé…ç½®")),
            "Secret Key": mask_sensitive_info(os.getenv("S3_SECRET_KEY", "æœªé…ç½®"))
        }
        
        for key, value in s3_config.items():
            if value == "æœªé…ç½®":
                st.error(f"âŒ {key}: {value}")
            else:
                st.info(f"ğŸ“‹ {key}: {value}")
    
    with col2:
        st.markdown("**S3æ“ä½œæµ‹è¯•**")
        
        if st.button("ğŸ” æµ‹è¯•S3è¿æ¥", key="test_s3"):
            with st.spinner("æµ‹è¯•S3è¿æ¥ä¸­..."):
                result = test_s3_operations()
                
                if result['success']:
                    st.success("âœ… S3è¿æ¥æµ‹è¯•æˆåŠŸï¼")
                    
                    if result.get('bucket_exists'):
                        st.info("ğŸ“¦ å­˜å‚¨æ¡¶å¯è®¿é—®")
                    
                    if result.get('test_upload'):
                        st.info("ğŸ“¤ ä¸Šä¼ æƒé™æ­£å¸¸")
                    
                    if result.get('test_download'):
                        st.info("ğŸ“¥ ä¸‹è½½æƒé™æ­£å¸¸")
                else:
                    st.error(f"âŒ S3è¿æ¥æµ‹è¯•å¤±è´¥: {result.get('error')}")
        
        st.markdown("**å­˜å‚¨ç»Ÿè®¡**")
        if s3_status['connected']:
            stats = get_s3_storage_stats()
            if stats:
                st.metric("å­˜å‚¨çš„æ–‡æ¡£æ•°é‡", stats.get('total_files', 'N/A'))
                st.metric("æ€»å­˜å‚¨å¤§å°", stats.get('total_size', 'N/A'))
            else:
                st.info("æ— æ³•è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯")

def show_ai_settings():
    """æ˜¾ç¤ºAIé…ç½®"""
    st.subheader("ğŸ¤– AIåˆ†æé…ç½®")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**OpenAIé…ç½®**")
        
        openai_key = os.getenv("OPENAI_API_KEY")
        if openai_key:
            st.success("âœ… OpenAI APIå¯†é’¥å·²é…ç½®")
            st.code(f"API Key: {mask_sensitive_info(openai_key)}")
        else:
            st.error("âŒ OpenAI APIå¯†é’¥æœªé…ç½®")
        
        # æµ‹è¯•OpenAIè¿æ¥
        if st.button("ğŸ§ª æµ‹è¯•AIåˆ†æ", key="test_openai"):
            if not openai_key:
                st.error("è¯·å…ˆé…ç½®OpenAI APIå¯†é’¥")
            else:
                with st.spinner("æµ‹è¯•AIåˆ†æåŠŸèƒ½..."):
                    result = test_ai_analysis()
                    
                    if result['success']:
                        st.success("âœ… AIåˆ†ææµ‹è¯•æˆåŠŸï¼")
                        st.json(result.get('analysis_result', {}))
                    else:
                        st.error(f"âŒ AIåˆ†ææµ‹è¯•å¤±è´¥: {result.get('error')}")
    
    with col2:
        st.markdown("**AIåˆ†æç»Ÿè®¡**")
        
        ai_stats = get_ai_analysis_stats()
        if ai_stats:
            st.metric("æ€»åˆ†ææ¬¡æ•°", ai_stats.get('total_analyzed', 0))
            st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{ai_stats.get('avg_confidence', 0):.1f}%")
            st.metric("é€šè¿‡ç‡", f"{ai_stats.get('pass_rate', 0):.1f}%")
        
        st.markdown("**æ¨¡å‹ä¿¡æ¯**")
        st.info("ğŸš€ å½“å‰ä½¿ç”¨æ¨¡å‹: GPT-5")
        st.caption("GPT-5 äº2025å¹´8æœˆ7æ—¥å‘å¸ƒï¼Œæ˜¯æœ€æ–°çš„AIæ¨¡å‹")

def show_dify_settings():
    """æ˜¾ç¤ºDifyé›†æˆé…ç½®"""
    st.subheader("ğŸ“š DifyçŸ¥è¯†åº“é›†æˆ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Difyé…ç½®**")
        
        dify_config = {
            "API Key": os.getenv("DIFY_API_KEY", "æœªé…ç½®"),
            "Base URL": os.getenv("DIFY_BASE_URL", "https://api.dify.ai"),
            "Dataset ID": os.getenv("DIFY_DATASET_ID", "æœªé…ç½®")
        }
        
        for key, value in dify_config.items():
            if value == "æœªé…ç½®":
                st.error(f"âŒ {key}: {value}")
            elif key == "API Key":
                st.success(f"âœ… {key}: {mask_sensitive_info(value)}")
            else:
                st.info(f"ğŸ“‹ {key}: {value}")
        
        # æµ‹è¯•Difyè¿æ¥
        if st.button("ğŸ”— æµ‹è¯•Difyè¿æ¥", key="test_dify"):
            if dify_config["API Key"] == "æœªé…ç½®":
                st.error("è¯·å…ˆé…ç½®Dify APIå¯†é’¥")
            else:
                with st.spinner("æµ‹è¯•Difyè¿æ¥..."):
                    result = test_dify_connection()
                    
                    if result['success']:
                        st.success("âœ… Difyè¿æ¥æµ‹è¯•æˆåŠŸï¼")
                    else:
                        st.error(f"âŒ Difyè¿æ¥æµ‹è¯•å¤±è´¥: {result.get('error')}")
    
    with col2:
        st.markdown("**çŸ¥è¯†åº“ç»Ÿè®¡**")
        
        kb_stats = get_knowledge_base_stats()
        if kb_stats:
            st.metric("çŸ¥è¯†åº“æ–‡æ¡£æ•°é‡", kb_stats.get('total_documents', 'N/A'))
            st.metric("ä»Šæ—¥æ–°å¢", kb_stats.get('today_added', 'N/A'))
            st.metric("æˆåŠŸç‡", f"{kb_stats.get('success_rate', 0):.1f}%")
        else:
            st.info("æ— æ³•è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯")
        
        st.markdown("**æ“ä½œå†å²**")
        if st.button("ğŸ“‹ æŸ¥çœ‹æ“ä½œæ—¥å¿—", key="view_dify_logs"):
            st.info("Difyæ“ä½œæ—¥å¿—åŠŸèƒ½å¾…å®ç°")

def show_system_health():
    """æ˜¾ç¤ºç³»ç»Ÿå¥åº·çŠ¶æ€"""
    st.subheader("ğŸ¥ ç³»ç»Ÿå¥åº·ç›‘æ§")
    
    # æ•´ä½“å¥åº·çŠ¶æ€
    health_status = get_system_health()
    
    if health_status['overall'] == 'healthy':
        st.success("ğŸŸ¢ ç³»ç»Ÿæ•´ä½“çŠ¶æ€: å¥åº·")
    elif health_status['overall'] == 'warning':
        st.warning("ğŸŸ¡ ç³»ç»Ÿæ•´ä½“çŠ¶æ€: è­¦å‘Š")
    else:
        st.error("ğŸ”´ ç³»ç»Ÿæ•´ä½“çŠ¶æ€: å¼‚å¸¸")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**æœåŠ¡çŠ¶æ€**")
        
        services = {
            "FastAPIåç«¯": health_status.get('api_server', False),
            "Celeryå·¥ä½œè¿›ç¨‹": health_status.get('celery_worker', False),
            "æ•°æ®åº“": health_status.get('database', False),
            "Redis": health_status.get('redis', False),
            "S3å­˜å‚¨": health_status.get('s3', False)
        }
        
        for service, status in services.items():
            icon = "âœ…" if status else "âŒ"
            st.markdown(f"{icon} {service}")
    
    with col2:
        st.markdown("**ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€**")
        
        queue_stats = get_queue_statistics()
        if queue_stats:
            st.metric("å¾…å¤„ç†ä»»åŠ¡", queue_stats.get('pending_tasks', 0))
            st.metric("æ­£åœ¨å¤„ç†", queue_stats.get('active_tasks', 0))
            st.metric("å·²å®Œæˆ", queue_stats.get('completed_tasks', 0))
            st.metric("å¤±è´¥ä»»åŠ¡", queue_stats.get('failed_tasks', 0))
        
        if st.button("ğŸ”„ åˆ·æ–°å¥åº·çŠ¶æ€", key="refresh_health"):
            st.rerun()
    
    # ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
    st.markdown("**ç³»ç»Ÿèµ„æº**")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("CPUä½¿ç”¨ç‡", "N/A")  # éœ€è¦å®é™…å®ç°
    
    with col2:
        st.metric("å†…å­˜ä½¿ç”¨", "N/A")  # éœ€è¦å®é™…å®ç°
    
    with col3:
        st.metric("ç£ç›˜ç©ºé—´", "N/A")  # éœ€è¦å®é™…å®ç°
    
    # æœ€è¿‘é”™è¯¯æ—¥å¿—
    st.markdown("**æœ€è¿‘é”™è¯¯**")
    recent_errors = get_recent_errors()
    if recent_errors:
        for error in recent_errors[:5]:
            st.error(f"âŒ {error['timestamp']}: {error['message']}")
    else:
        st.success("âœ… æš‚æ— é”™è¯¯è®°å½•")

# è¾…åŠ©å‡½æ•°

def mask_sensitive_info(text, mask_char="*", show_last=4):
    """è„±æ•æ˜¾ç¤ºæ•æ„Ÿä¿¡æ¯"""
    if not text or text == "æœªé…ç½®":
        return text
    
    if len(text) <= show_last:
        return mask_char * len(text)
    
    return mask_char * (len(text) - show_last) + text[-show_last:]

def check_database_connection():
    """æ£€æŸ¥æ•°æ®åº“è¿æ¥"""
    try:
        response = requests.get("http://localhost:8000/health", timeout=5)
        return response.status_code == 200
    except Exception:
        return False

def check_redis_connection():
    """æ£€æŸ¥Redisè¿æ¥"""
    try:
        # TODO: å®ç°å®é™…çš„Redisè¿æ¥æ£€æŸ¥
        return True
    except Exception:
        return False

def check_s3_connection():
    """æ£€æŸ¥S3è¿æ¥"""
    try:
        # TODO: å®ç°å®é™…çš„S3è¿æ¥æ£€æŸ¥
        # å¯ä»¥è°ƒç”¨åç«¯APIä¸­çš„S3æœåŠ¡
        return {'connected': True}
    except Exception as e:
        return {'connected': False, 'error': str(e)}

def test_s3_operations():
    """æµ‹è¯•S3æ“ä½œ"""
    try:
        # TODO: å®ç°S3æ“ä½œæµ‹è¯•
        # åŒ…æ‹¬å­˜å‚¨æ¡¶è®¿é—®ã€ä¸Šä¼ ã€ä¸‹è½½æµ‹è¯•
        return {
            'success': True,
            'bucket_exists': True,
            'test_upload': True,
            'test_download': True
        }
    except Exception as e:
        return {'success': False, 'error': str(e)}

def get_s3_storage_stats():
    """è·å–S3å­˜å‚¨ç»Ÿè®¡"""
    try:
        # TODO: å®ç°S3å­˜å‚¨ç»Ÿè®¡
        return {
            'total_files': 1250,
            'total_size': '2.5 GB'
        }
    except Exception:
        return None

def test_ai_analysis():
    """æµ‹è¯•AIåˆ†æåŠŸèƒ½"""
    try:
        # TODO: å®ç°AIåˆ†ææµ‹è¯•
        # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æµ‹è¯•æ–‡æœ¬è¿›è¡Œåˆ†æ
        return {
            'success': True,
            'analysis_result': {
                'suitable_for_kb': True,
                'confidence_score': 85,
                'category': 'test',
                'summary': 'AIåˆ†ææµ‹è¯•æˆåŠŸ'
            }
        }
    except Exception as e:
        return {'success': False, 'error': str(e)}

def get_ai_analysis_stats():
    """è·å–AIåˆ†æç»Ÿè®¡"""
    try:
        # ä»ä»ªè¡¨æ¿APIè·å–ç»Ÿè®¡æ•°æ®
        response = requests.get("http://localhost:8000/api/v1/statistics/dashboard", timeout=5)
        if response.status_code == 200:
            data = response.json()
            total_files = data.get('total_files', 0)
            completed = data.get('today_completed', 0)
            total_processed = data.get('today_processed', 1)  # é¿å…é™¤é›¶
            
            return {
                'total_analyzed': total_files,
                'avg_confidence': 0,  # TODO: éœ€è¦æ–°çš„APIæ¥å£
                'pass_rate': (completed / max(total_processed, 1)) * 100
            }
        return None
    except Exception:
        return None

def test_dify_connection():
    """æµ‹è¯•Difyè¿æ¥"""
    try:
        # TODO: å®ç°Difyè¿æ¥æµ‹è¯•
        return {'success': True}
    except Exception as e:
        return {'success': False, 'error': str(e)}

def get_knowledge_base_stats():
    """è·å–çŸ¥è¯†åº“ç»Ÿè®¡"""
    try:
        # TODO: ä»Dify APIè·å–çŸ¥è¯†åº“ç»Ÿè®¡
        return {
            'total_documents': 523,
            'today_added': 15,
            'success_rate': 94.2
        }
    except Exception:
        return None

def get_system_health():
    """è·å–ç³»ç»Ÿå¥åº·çŠ¶æ€"""
    try:
        # æ£€æŸ¥APIæœåŠ¡å™¨
        api_healthy = False
        try:
            response = requests.get("http://localhost:8000/health", timeout=5)
            api_healthy = response.status_code == 200
        except:
            pass
        
        # æ£€æŸ¥æ•°æ®åº“
        db_healthy = check_database_connection()
        
        # æ£€æŸ¥Redis
        redis_healthy = check_redis_connection()
        
        # ç®€å•çš„å¥åº·è¯„ä¼°
        healthy_services = sum([api_healthy, db_healthy, redis_healthy])
        if healthy_services >= 2:
            overall = 'healthy'
        elif healthy_services >= 1:
            overall = 'warning'
        else:
            overall = 'error'
            
        return {
            'overall': overall,
            'api_server': api_healthy,
            'celery_worker': False,  # TODO: å®ç°Celeryæ£€æŸ¥
            'database': db_healthy,
            'redis': redis_healthy,
            's3': False  # TODO: å®ç°S3æ£€æŸ¥
        }
    except Exception:
        return {
            'overall': 'error',
            'api_server': False,
            'celery_worker': False,
            'database': False,
            'redis': False,
            's3': False
        }

def get_queue_statistics():
    """è·å–ä»»åŠ¡é˜Ÿåˆ—ç»Ÿè®¡"""
    try:
        # TODO: ä»Celeryè·å–é˜Ÿåˆ—ç»Ÿè®¡
        return {
            'pending_tasks': 12,
            'active_tasks': 3,
            'completed_tasks': 567,
            'failed_tasks': 23
        }
    except Exception:
        return None

def get_recent_errors():
    """è·å–æœ€è¿‘é”™è¯¯"""
    try:
        # TODO: ä»æ—¥å¿—æˆ–æ•°æ®åº“è·å–æœ€è¿‘é”™è¯¯
        return [
            {
                'timestamp': '2024-09-16 14:30:00',
                'message': 'S3ä¸‹è½½è¶…æ—¶: file_12345.pdf'
            },
            {
                'timestamp': '2024-09-16 13:45:00',
                'message': 'AIåˆ†æAPIè°ƒç”¨å¤±è´¥'
            }
        ]
    except Exception:
        return []
