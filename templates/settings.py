import streamlit as st
import os
import requests
import json
import sys
from datetime import datetime
from typing import Any, Dict, List, Optional

# æ·»åŠ utilsç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from utils.api_config import get_statistics_api_url, get_system_api_url, get_files_api_url
from config import settings


def show_settings():
    """æ˜¾ç¤ºç³»ç»Ÿè®¾ç½®é¡µé¢"""
    st.title("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
    st.markdown("é…ç½®å’Œç®¡ç†OAæ–‡æ¡£å¤„ç†ç³»ç»Ÿçš„å„é¡¹å‚æ•°")

    # æ·»åŠ APIè¿æ¥æµ‹è¯•
    st.markdown("### ğŸ”— APIè¿æ¥æµ‹è¯•")
    col1, col2, col3 = st.columns([1, 1, 3])
    
    with col1:
        if st.button("ğŸ”„ åˆ·æ–°çŠ¶æ€", key="settings_refresh"):
            st.rerun()
    
    with col2:
        if st.button("ğŸ§ª æµ‹è¯•APIè¿æ¥", key="test_api_connection"):
            test_api_connection()
    
    st.markdown("---")

    system_snapshot = load_system_snapshot()
    s3_overview = load_s3_overview()
    dify_overview = load_dify_overview()

    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ”§ åŸºæœ¬é…ç½®",
        "â˜ï¸ S3å­˜å‚¨",
        "ğŸ¤– AIé…ç½®",
        "ğŸ“š Difyé›†æˆ",
        "ğŸ¥ ç³»ç»Ÿå¥åº·",
    ])

    with tab1:
        show_basic_settings(system_snapshot, s3_overview, dify_overview)

    with tab2:
        show_s3_settings(system_snapshot, s3_overview)

    with tab3:
        show_ai_settings(system_snapshot)

    with tab4:
        show_dify_settings(dify_overview)

    with tab5:
        show_system_health(system_snapshot, s3_overview, dify_overview)


def load_system_snapshot() -> Dict[str, Any]:
    """è°ƒç”¨åç«¯è·å–ç³»ç»ŸçŠ¶æ€å¿«ç…§"""
    try:
        url = get_system_api_url("status")
        response = requests.get(url, timeout=30)  # å¢åŠ è¶…æ—¶æ—¶é—´
        response.raise_for_status()
        data = response.json()
        return data
    except requests.RequestException as exc:
        st.error(f"âŒ è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {exc}")
        st.info("ğŸ’¡ æç¤ºï¼šå¦‚æœæ˜¯è¶…æ—¶é”™è¯¯ï¼Œå¯èƒ½æ˜¯æ•°æ®åº“æŸ¥è¯¢è¾ƒæ…¢ï¼Œè¯·ç¨åé‡è¯•")
        return {}


def load_s3_overview() -> Dict[str, Any]:
    """è·å–S3çŠ¶æ€å’Œç»Ÿè®¡ä¿¡æ¯"""
    try:
        url = get_system_api_url("s3")
        response = requests.get(url, timeout=15)
        response.raise_for_status()
        data = response.json()
        return data
    except requests.RequestException as exc:
        st.error(f"âŒ è·å–S3çŠ¶æ€å¤±è´¥: {exc}")
        return {}


def load_dify_overview() -> Dict[str, Any]:
    """è·å–Difyé›†æˆçŠ¶æ€"""
    try:
        url = get_system_api_url("dify")
        response = requests.get(url, timeout=15)
        response.raise_for_status()
        data = response.json()
        return data
    except requests.RequestException as exc:
        st.error(f"âŒ è·å–DifyçŠ¶æ€å¤±è´¥: {exc}")
        if "401" in str(exc) or "unauthorized" in str(exc).lower():
            st.info("ğŸ’¡ æç¤ºï¼šDify APIå¯†é’¥å¯èƒ½æ— æ•ˆï¼Œè¯·æ£€æŸ¥DIFY_API_KEYç¯å¢ƒå˜é‡")
        return {}


def show_basic_settings(system_snapshot: Dict[str, Any], s3_overview: Dict[str, Any], dify_overview: Dict[str, Any]):
    """æ˜¾ç¤ºåŸºæœ¬é…ç½®"""
    st.subheader("ğŸ“‹ åŸºæœ¬é…ç½®")

    database_status = system_snapshot.get("database", {})
    redis_status = system_snapshot.get("redis", {})

    col1, col2 = st.columns(2)

    with col1:
        render_connection_status("æ•°æ®åº“", database_status)

        db_url = os.getenv("DATABASE_URL", "æœªé…ç½®")
        if db_url != "æœªé…ç½®":
            st.code(f"æ•°æ®åº“URL: {mask_sensitive_info(db_url)}")
        else:
            st.warning("âš ï¸ DATABASE_URL æœªé…ç½®")

        st.markdown("**æ–‡æ¡£å¤„ç†é…ç½®**")
        max_file_size_mb = settings.max_file_size / (1024 * 1024)
        st.info(f"ğŸ“ æœ€å¤§æ–‡ä»¶å¤§å°: {max_file_size_mb:.0f} MB")
        st.info(f"ğŸ“„ æ”¯æŒçš„æ ¼å¼: {', '.join(settings.supported_formats)}")

    with col2:
        render_connection_status("Redis", redis_status)
        st.code(f"Redis URL: {mask_sensitive_info(settings.redis_url)}")

        if redis_status.get("connected"):
            redis_meta = []
            if redis_status.get("version"):
                redis_meta.append(f"ç‰ˆæœ¬: {redis_status['version']}")
            if redis_status.get("used_memory_human"):
                redis_meta.append(f"å†…å­˜å ç”¨: {redis_status['used_memory_human']}")
            if redis_meta:
                st.caption(" | ".join(redis_meta))

        st.markdown("**ç¯å¢ƒå˜é‡æ£€æŸ¥**")
        required_vars = [
            "DATABASE_URL",
            "REDIS_URL",
            "S3_ACCESS_KEY",
            "S3_SECRET_KEY",
            "OPENAI_API_KEY",
            "DIFY_API_KEY",
        ]
        env_cols = st.columns(2)
        for idx, var in enumerate(required_vars):
            with env_cols[idx % 2]:
                value = os.getenv(var)
                if value:
                    st.success(f"âœ… {var}")
                else:
                    st.error(f"âŒ {var} - æœªè®¾ç½®")

    st.markdown("**å¾…åŠäº‹é¡¹**")
    todo_items = build_todo_items(system_snapshot, s3_overview, dify_overview)
    if todo_items:
        for item in todo_items:
            st.warning(f"â€¢ {item}")
    else:
        st.success("æš‚æ— å¾…åŠäº‹é¡¹")


def show_s3_settings(system_snapshot: Dict[str, Any], s3_overview: Dict[str, Any]):
    """æ˜¾ç¤ºS3å­˜å‚¨é…ç½®"""
    st.subheader("â˜ï¸ S3å­˜å‚¨é…ç½®")

    status = system_snapshot.get("s3", {})
    render_connection_status("S3", status)

    config = s3_overview.get("config", {})
    st.markdown("**è¿æ¥é…ç½®**")
    st.code(
        json.dumps(
            {
                "Bucket": config.get("bucket", "æœªé…ç½®"),
                "Region": config.get("region", "æœªé…ç½®"),
                "Endpoint": config.get("endpoint", "é»˜è®¤"),
                "Access Key": mask_sensitive_info(os.getenv("S3_ACCESS_KEY", "æœªé…ç½®")),
                "Secret Key": mask_sensitive_info(os.getenv("S3_SECRET_KEY", "æœªé…ç½®")),
            },
            ensure_ascii=False,
            indent=2,
        )
    )

    stats = s3_overview.get("stats")
    if stats and stats.get("success", True):
        st.markdown("**å­˜å‚¨ç»Ÿè®¡ (é‡‡æ ·)**")
        metric_cols = st.columns(3)
        with metric_cols[0]:
            st.metric("å¯¹è±¡æ•°é‡ (é‡‡æ ·)", stats.get("object_count_sample", 0))
        with metric_cols[1]:
            st.metric("æ€»å¤§å° (é‡‡æ ·)", format_bytes(stats.get("total_size_bytes_sample", 0)))
        with metric_cols[2]:
            st.metric("æ˜¯å¦å®Œæ•´æ‰«æ", "æ˜¯" if stats.get("sample_complete") else "å¦")
    else:
        st.info("æš‚æ— S3å­˜å‚¨ç»Ÿè®¡æ•°æ®")

    if st.button("ğŸ§ª è¿è¡ŒS3è¯Šæ–­", key="s3_diagnostics"):
        result = trigger_s3_diagnostics()
        if result.get("success"):
            st.success("S3è¯Šæ–­å®Œæˆ")
            inspected = result.get("diagnostics", {}).get("inspected_object")
            if inspected:
                st.caption(
                    f"ç¤ºä¾‹å¯¹è±¡: {inspected.get('key')} | å¤§å°: {format_bytes(inspected.get('size', 0))}"
                )
        else:
            st.error(f"è¯Šæ–­å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")


def show_ai_settings(system_snapshot: Dict[str, Any]):
    """æ˜¾ç¤ºAIé…ç½®ä¸ç»Ÿè®¡"""
    st.subheader("ğŸ¤– AIé…ç½®")

    stats = get_ai_analysis_stats()
    if stats:
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€»æ–‡æ¡£æ•°", stats.get("total_analyzed", 0))
        with col2:
            st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{stats.get('avg_confidence', 0):.1f}%")
        with col3:
            st.metric("ä»Šæ—¥æˆåŠŸç‡", f"{stats.get('pass_rate', 0):.1f}%")
    else:
        st.info("æš‚æ— AIç»Ÿè®¡æ•°æ®")

    st.markdown("**AIåŠŸèƒ½è‡ªæ£€**")
    if st.button("ğŸ§ª è¿è¡ŒAIåˆ†æè‡ªæ£€", key="ai_self_test"):
        result = test_ai_analysis()
        if result.get("success"):
            st.success("AIåˆ†æç»„ä»¶è¿è¡Œæ­£å¸¸")
            st.caption("å·²é€šè¿‡ç¤ºä¾‹æ–‡æœ¬å®Œæˆåˆ†æ")
        else:
            st.error(f"AIåˆ†æè‡ªæ£€å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")


def show_dify_settings(dify_overview: Dict[str, Any]):
    """æ˜¾ç¤ºDifyé›†æˆä¿¡æ¯"""
    st.subheader("ğŸ“š Difyé›†æˆ")

    connection = dify_overview.get("connection", {})
    if connection.get("success"):
        st.success("âœ… Dify APIè¿æ¥æ­£å¸¸")
        st.caption(connection.get("message", "APIè¿”å›æˆåŠŸ"))
    else:
        st.error(f"âŒ Dify APIè¿æ¥å¼‚å¸¸: {connection.get('error', 'æœªçŸ¥é”™è¯¯')}")

    if st.button("ğŸ” æµ‹è¯•Difyè¿æ¥", key="dify_test"):
        result = trigger_dify_test()
        if result.get("success"):
            st.success("Difyè¿æ¥æµ‹è¯•é€šè¿‡")
        else:
            st.error(f"è¿æ¥å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

    dataset = dify_overview.get("dataset", {})
    document_total = dify_overview.get("document_total")
    pagination = dify_overview.get("pagination", {})

    st.markdown("**çŸ¥è¯†åº“ä¿¡æ¯**")
    info_items = {
        "çŸ¥è¯†åº“åç§°": dataset.get("name", "æœªé…ç½®"),
        "æ•°æ®é›†ID": settings.dify_dataset_id or "æœªé…ç½®",
        "æ–‡æ¡£æ€»æ•°": document_total if document_total is not None else "æœªçŸ¥",
        "æœ€è¿‘æ›´æ–°": format_datetime(dataset.get("updated_at")) if dataset else "--",
    }
    st.code(json.dumps(info_items, ensure_ascii=False, indent=2))

    if pagination:
        st.caption(
            f"åˆ†é¡µä¿¡æ¯: æ€»æ•° {pagination.get('total', 'æœªçŸ¥')} | æ¯é¡µ {pagination.get('limit', 'æœªçŸ¥')}"
        )


def show_system_health(system_snapshot: Dict[str, Any], s3_overview: Dict[str, Any], dify_overview: Dict[str, Any]):
    """æ˜¾ç¤ºç³»ç»Ÿå¥åº·çŠ¶æ€"""
    st.subheader("ğŸ¥ ç³»ç»Ÿå¥åº·")

    overall = system_snapshot.get("overall", "unknown")
    status_emoji = {
        "healthy": "ğŸŸ¢",
        "warning": "ğŸŸ¡",
        "error": "ğŸ”´",
    }.get(overall, "âšª")
    st.markdown(f"### {status_emoji} ç»¼åˆçŠ¶æ€: {overall.upper()}")

    services = {
        "API": system_snapshot.get("database", {}),
        "Redis": system_snapshot.get("redis", {}),
        "S3": system_snapshot.get("s3", {}),
        "Celery": system_snapshot.get("celery", {}),
    }
    service_cols = st.columns(len(services))
    for col, (label, status) in zip(service_cols, services.items()):
        with col:
            render_connection_status(label, status)

    queue = system_snapshot.get("queue", {})
    st.markdown("**å¤„ç†é˜Ÿåˆ—æ¦‚è§ˆ**")
    queue_cols = st.columns(4)
    queue_metrics = [
        ("å¾…å¤„ç†", queue.get("PENDING", 0)),
        ("å¤„ç†ä¸­", queue.get("in_progress", 0)),
        ("å¾…å®¡æ ¸", queue.get("AWAITING_APPROVAL", 0)),
        ("å¤±è´¥", queue.get("FAILED", 0)),
    ]
    for col, (label, value) in zip(queue_cols, queue_metrics):
        with col:
            st.metric(label, value)

    st.markdown("**æœ€è¿‘é”™è¯¯**")
    recent_errors = system_snapshot.get("recent_errors", [])
    if recent_errors:
        for item in recent_errors:
            message = item.get("message", "")
            timestamp = format_datetime(item.get("created_at"))
            st.error(f"{timestamp or '--'} â€” {message}")
    else:
        st.success("âœ… æš‚æ— é”™è¯¯è®°å½•")

    st.markdown("**æœ€æ–°æ´»åŠ¨**")
    recent_activity = system_snapshot.get("recent_activity", [])
    if recent_activity:
        activity_rows = []
        for row in recent_activity:
            activity_rows.append(
                {
                    "æ—¶é—´": format_datetime(row.get("created_at")),
                    "æ–‡ä»¶ID": row.get("file_id"),
                    "æ­¥éª¤": row.get("step"),
                    "çŠ¶æ€": row.get("status"),
                    "è€—æ—¶(s)": row.get("duration_seconds"),
                }
            )
        st.dataframe(activity_rows, use_container_width=True, hide_index=True)
    else:
        st.info("æš‚æ— æ´»åŠ¨æ—¥å¿—")


# --- è¾…åŠ©å‡½æ•° ---

def render_connection_status(label: str, status: Dict[str, Any]):
    """ç»Ÿä¸€æ¸²æŸ“è¿æ¥çŠ¶æ€"""
    if status.get("connected"):
        extra = []
        if status.get("workers"):
            extra.append(f"Workers: {len(status['workers'])}")
        if status.get("active_tasks") is not None:
            extra.append(f"æ´»è·ƒä»»åŠ¡: {status['active_tasks']}")
        message = " | ".join(extra) if extra else "è¿è¡Œæ­£å¸¸"
        st.success(f"âœ… {label} è¿æ¥æ­£å¸¸")
        if message:
            st.caption(message)
    else:
        error = status.get("error") or "æœªçŸ¥é”™è¯¯"
        st.error(f"âŒ {label} è¿æ¥å¼‚å¸¸: {error}")


def build_todo_items(system_snapshot: Dict[str, Any], s3_overview: Dict[str, Any], dify_overview: Dict[str, Any]) -> List[str]:
    """æ ¹æ®å½“å‰çŠ¶æ€ç”Ÿæˆå¾…åŠäº‹é¡¹"""
    items: List[str] = []

    if not system_snapshot.get("database", {}).get("connected"):
        items.append("æ£€æŸ¥æ•°æ®åº“è¿æ¥é…ç½®å’ŒæœåŠ¡çŠ¶æ€")
    if not system_snapshot.get("redis", {}).get("connected"):
        items.append("ç¡®è®¤RedisæœåŠ¡åœ°å€ä¸å‡­è¯é…ç½®")
    if not system_snapshot.get("s3", {}).get("connected"):
        items.append("å®Œå–„S3å­˜å‚¨é…ç½®å¹¶ç¡®ä¿Bucketå¯è®¿é—®")
    if not system_snapshot.get("celery", {}).get("connected"):
        items.append("å¯åŠ¨å¹¶æ³¨å†ŒCelery Worker ä»¥å¤„ç†åå°ä»»åŠ¡")

    connection = dify_overview.get("connection", {})
    if connection and not connection.get("success"):
        items.append("æ ¡éªŒDify APIå¯†é’¥ä¸çŸ¥è¯†åº“IDé…ç½®")

    if not os.getenv("OPENAI_API_KEY"):
        items.append("è®¾ç½® OPENAI_API_KEY ä»¥å¯ç”¨AIåˆ†æèƒ½åŠ›")

    return list(dict.fromkeys(items))


def trigger_s3_diagnostics() -> Dict[str, Any]:
    """è°ƒç”¨åç«¯æ‰§è¡ŒS3è¯Šæ–­"""
    try:
        url = get_system_api_url("s3/test")
        st.write(f"Debug: æ­£åœ¨è°ƒç”¨S3è¯Šæ–­API: {url}")  # è°ƒè¯•ä¿¡æ¯
        response = requests.post(url, timeout=20)
        response.raise_for_status()
        data = response.json()
        st.success(f"âœ… S3è¯Šæ–­APIè°ƒç”¨æˆåŠŸ")
        return data
    except requests.RequestException as exc:
        st.error(f"âŒ S3è¯Šæ–­APIè°ƒç”¨å¤±è´¥: {exc}")
        st.write(f"Debug: S3è¯Šæ–­API URL: {url}")
        return {"success": False, "error": str(exc)}


def trigger_dify_test() -> Dict[str, Any]:
    """è°ƒç”¨åç«¯æµ‹è¯•Difyè¿æ¥"""
    try:
        url = get_system_api_url("dify/test")
        st.write(f"Debug: æ­£åœ¨è°ƒç”¨Difyæµ‹è¯•API: {url}")  # è°ƒè¯•ä¿¡æ¯
        response = requests.post(url, timeout=10)
        response.raise_for_status()
        data = response.json()
        st.success(f"âœ… Difyæµ‹è¯•APIè°ƒç”¨æˆåŠŸ")
        return data
    except requests.RequestException as exc:
        st.error(f"âŒ Difyæµ‹è¯•APIè°ƒç”¨å¤±è´¥: {exc}")
        st.write(f"Debug: Difyæµ‹è¯•API URL: {url}")
        return {"success": False, "error": str(exc)}


def format_bytes(size_in_bytes: Optional[int]) -> str:
    """å°†å­—èŠ‚å¤§å°è½¬æ¢ä¸ºå¯è¯»æ ¼å¼"""
    if not size_in_bytes:
        return "0 B"
    units = ["B", "KB", "MB", "GB", "TB"]
    size = float(size_in_bytes)
    for unit in units:
        if size < 1024:
            return f"{size:.2f} {unit}"
        size /= 1024
    return f"{size:.2f} PB"


def format_datetime(value: Optional[str]) -> Optional[str]:
    """æ ¼å¼åŒ–ISOæ—¥æœŸå­—ç¬¦ä¸²"""
    if not value:
        return None
    try:
        dt = datetime.fromisoformat(value.replace("Z", "+00:00"))
        return dt.strftime("%Y-%m-%d %H:%M:%S")
    except ValueError:
        return value


def mask_sensitive_info(text: Optional[str], mask_char: str = "*", show_last: int = 4) -> Optional[str]:
    """è„±æ•æ˜¾ç¤ºæ•æ„Ÿä¿¡æ¯"""
    if not text or text == "æœªé…ç½®":
        return text
    if len(text) <= show_last:
        return mask_char * len(text)
    return mask_char * (len(text) - show_last) + text[-show_last:]


def get_ai_analysis_stats() -> Optional[Dict[str, Any]]:
    """è·å–AIåˆ†æç»Ÿè®¡æ•°æ®"""
    try:
        url = get_statistics_api_url("dashboard")
        response = requests.get(url, timeout=15)
        response.raise_for_status()
        data = response.json()

        total_files = data.get("total_files", 0)
        completed = data.get("today_completed", 0)
        total_processed = data.get("today_processed", 1)

        files_url = f"{get_files_api_url()}?page=1&size=50"
        files_resp = requests.get(files_url, timeout=15)
        files_resp.raise_for_status()
        files_data = files_resp.json()
        items = files_data.get("items", [])
        confidences = [item.get("ai_confidence_score") for item in items if item.get("ai_confidence_score") is not None]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0

        return {
            "total_analyzed": total_files,
            "avg_confidence": avg_confidence,
            "pass_rate": (completed / max(total_processed, 1)) * 100,
        }
    except requests.RequestException as exc:
        st.error(f"âŒ è·å–AIç»Ÿè®¡æ•°æ®å¤±è´¥: {exc}")
        return None


def test_ai_analysis() -> Dict[str, Any]:
    """æµ‹è¯•AIåˆ†æåŠŸèƒ½"""
    try:
        from services.ai_analyzer import ai_analyzer

        test_content = """
        è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ï¼Œç”¨äºéªŒè¯AIåˆ†æåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚
        æ–‡æ¡£åŒ…å«äº†ä¸€äº›åŸºæœ¬çš„ä¸šåŠ¡ä¿¡æ¯å’Œæ“ä½œæŒ‡å—ã€‚
        è¯¥æ–‡æ¡£ç”¨äºæµ‹è¯•ç³»ç»Ÿçš„æ–‡æ¡£åˆ†æèƒ½åŠ›ã€‚
        """

        test_metadata = {
            'file_type': 'txt',
            'pages': 1
        }

        result = ai_analyzer.analyze_document_content(
            content=test_content,
            filename="test_document.txt",
            metadata=test_metadata
        )

        return {
            'success': True,
            'analysis_result': result
        }
    except Exception as exc:
        return {'success': False, 'error': str(exc)}


def test_api_connection():
    """æµ‹è¯•APIè¿æ¥"""
    st.markdown("**APIè¿æ¥æµ‹è¯•ç»“æœï¼š**")
    
    # æµ‹è¯•åŸºç¡€å¥åº·æ£€æŸ¥
    try:
        from utils.api_config import get_health_check_url
        health_url = get_health_check_url()
        response = requests.get(health_url, timeout=10)
        response.raise_for_status()
        st.success("âœ… åŸºç¡€APIè¿æ¥æ­£å¸¸")
    except Exception as e:
        st.error(f"âŒ åŸºç¡€APIè¿æ¥å¤±è´¥: {e}")
    
    # æµ‹è¯•ç³»ç»ŸçŠ¶æ€API
    try:
        url = get_system_api_url("status")
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        st.success("âœ… ç³»ç»ŸçŠ¶æ€APIè¿æ¥æ­£å¸¸")
    except Exception as e:
        st.error(f"âŒ ç³»ç»ŸçŠ¶æ€APIè¿æ¥å¤±è´¥: {e}")
        if "timeout" in str(e).lower():
            st.info("ğŸ’¡ æç¤ºï¼šç³»ç»ŸçŠ¶æ€APIè¶…æ—¶ï¼Œå¯èƒ½æ˜¯æ•°æ®åº“æŸ¥è¯¢è¾ƒæ…¢")
    
    # æ˜¾ç¤ºå½“å‰APIé…ç½®
    from utils.api_config import api_config
    st.markdown("**å½“å‰APIé…ç½®ï¼š**")
    st.code(f"""
APIåŸºç¡€URL: {api_config.base_url}
è¿è¡Œç¯å¢ƒ: {'Dockerå®¹å™¨' if api_config._is_running_in_docker() else 'å¼€å‘ç¯å¢ƒ'}
ç¯å¢ƒå˜é‡API_BASE_URL: {os.getenv('API_BASE_URL', 'æœªè®¾ç½®')}
    """)


def format_file_size(size_bytes: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if size_bytes == 0:
        return "0 B"

    size_names = ["B", "KB", "MB", "GB"]
    import math
    i = int(math.floor(math.log(size_bytes, 1024)))
    p = math.pow(1024, i)
    s = round(size_bytes / p, 2)
    return f"{s} {size_names[i]}"
